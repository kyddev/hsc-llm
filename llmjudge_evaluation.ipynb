{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM JUDGE EVALUATION SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tempfile\n",
    "\n",
    "import chromadb\n",
    "import streamlit as st\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from pypdf import PdfReader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import CrossEncoder\n",
    "from streamlit.runtime.uploaded_file_manager import UploadedFile\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load evaluator LLM\n",
    "evaluator_llm = ChatOllama(model=\"gemma2:9b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an evaluator for question and answers.\n",
    "\n",
    "You are given a: \n",
    "\n",
    "(1) question, \n",
    "(2) a candidate answer,\n",
    "(3) the marks allocated for the question if correctly evaluated, and\n",
    "(4) a criteria to evaluate the candidate answer.\n",
    "\n",
    "The criteria is a list of conditions that the candidate answer must satisfy to be awarded full marks.\n",
    "Each line will denote an extra mark that can be awarded.\n",
    "\n",
    "You need to evaluate the candidate answer based on the criteria.\n",
    "\n",
    "[QUESTION]: {question}\n",
    "\n",
    "[CANDIDATE ANSWER]: {candidate_answer}\n",
    "\n",
    "[TOTAL MARKS]: {marks}\n",
    "\n",
    "[CRITERIA]: {criteria}\n",
    "\n",
    "\n",
    "You must reply in the following format:\n",
    "\n",
    "[EVALUATED MARKS]: (answer here)\n",
    "\n",
    "[REASONING]: (answer here)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluations(question: str, marks: int, candidate_answer: str, criteria: str):\n",
    "    llm = evaluator_llm\n",
    "\n",
    "    evaluator_prompt = ChatPromptTemplate.from_template(system_prompt)\n",
    "\n",
    "    chain = evaluator_prompt | llm | StrOutputParser()\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"candidate_answer\": candidate_answer,\n",
    "        \"marks\": marks,\n",
    "        \"criteria\": criteria\n",
    "    })\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare input file for evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the calculation file\n",
    "combined_df = pd.read_csv(\"combined_df.csv\", index_col=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUESTION</th>\n",
       "      <th>ANSWER</th>\n",
       "      <th>MARKS</th>\n",
       "      <th>CRITERIA</th>\n",
       "      <th>Model1_GA</th>\n",
       "      <th>Model2_GA</th>\n",
       "      <th>Model1a_GA</th>\n",
       "      <th>Model2a_GA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Define the term ‘adaptation’</td>\n",
       "      <td>Adaptation are the inherited favourable charac...</td>\n",
       "      <td>1</td>\n",
       "      <td>1 mark = correctly definition of adaptation</td>\n",
       "      <td>The term \"adaptation\" refers to a trait or beh...</td>\n",
       "      <td>Adaptation refers to the process by which an o...</td>\n",
       "      <td>An adaptation is a characteristic that an orga...</td>\n",
       "      <td>An adaptation is a characteristic that an orga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Distinguish between sexual reproduction and as...</td>\n",
       "      <td>Sexual reproduction, such as meiosis, is the p...</td>\n",
       "      <td>4</td>\n",
       "      <td>1 mark = Define sexual reproduction\\r\\n\\r\\n1 m...</td>\n",
       "      <td>Sexual reproduction involves the combination o...</td>\n",
       "      <td>Sexual reproduction involves the combination o...</td>\n",
       "      <td>Reproduction ensures the continuity of a speci...</td>\n",
       "      <td>Reproduction ensures the continuity of a speci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             QUESTION  \\\n",
       "ID                                                      \n",
       "1                        Define the term ‘adaptation’   \n",
       "2   Distinguish between sexual reproduction and as...   \n",
       "\n",
       "                                               ANSWER  MARKS  \\\n",
       "ID                                                             \n",
       "1   Adaptation are the inherited favourable charac...      1   \n",
       "2   Sexual reproduction, such as meiosis, is the p...      4   \n",
       "\n",
       "                                             CRITERIA  \\\n",
       "ID                                                      \n",
       "1         1 mark = correctly definition of adaptation   \n",
       "2   1 mark = Define sexual reproduction\\r\\n\\r\\n1 m...   \n",
       "\n",
       "                                            Model1_GA  \\\n",
       "ID                                                      \n",
       "1   The term \"adaptation\" refers to a trait or beh...   \n",
       "2   Sexual reproduction involves the combination o...   \n",
       "\n",
       "                                            Model2_GA  \\\n",
       "ID                                                      \n",
       "1   Adaptation refers to the process by which an o...   \n",
       "2   Sexual reproduction involves the combination o...   \n",
       "\n",
       "                                           Model1a_GA  \\\n",
       "ID                                                      \n",
       "1   An adaptation is a characteristic that an orga...   \n",
       "2   Reproduction ensures the continuity of a speci...   \n",
       "\n",
       "                                           Model2a_GA  \n",
       "ID                                                     \n",
       "1   An adaptation is a characteristic that an orga...  \n",
       "2   Reproduction ensures the continuity of a speci...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the questions and answers\n",
    "questions = combined_df['QUESTION'].values.tolist()\n",
    "reference_answers = combined_df['ANSWER'].values.tolist()\n",
    "reference_marks = combined_df['MARKS'].values.tolist()\n",
    "criteria = combined_df['CRITERIA'].values.tolist()\n",
    "\n",
    "model1_answers = combined_df['Model1_GA'].values.tolist()\n",
    "model2_answers = combined_df['Model2_GA'].values.tolist()\n",
    "model1a_answers = combined_df['Model1a_GA'].values.tolist()\n",
    "model2a_answers = combined_df['Model2a_GA'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get evaluations for model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_evaluation = []\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    response = get_evaluations(questions[i], reference_marks[i], model1_answers[i], criteria[i])\n",
    "    model1_evaluation.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get evaluations for model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_evaluation = []\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    response = get_evaluations(questions[i], reference_marks[i], model2_answers[i], criteria[i])\n",
    "    model2_evaluation.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get evaluations for model 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1a_evaluation = []\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    response = get_evaluations(questions[i], reference_marks[i], model1a_answers[i], criteria[i])\n",
    "    model1a_evaluation.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get evaluations for model 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2a_evaluation = []\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    response = get_evaluations(questions[i], reference_marks[i], model2a_answers[i], criteria[i])\n",
    "    model2a_evaluation.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "\n",
    "for i in range(1, len(questions)+1):\n",
    "    index_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_response_df = pd.DataFrame({\n",
    "    \"ID\": index_list,\n",
    "    \"QUESTION\": questions,\n",
    "    \"REFERENCE_ANSWER\": reference_answers,\n",
    "    \"REFERENCE_MARKS\": reference_marks,\n",
    "    \"CRITERIA\": criteria,\n",
    "    \"MODEL1_ANSWER\": model1_answers,\n",
    "    \"MODEL1_EVALUATION\": model1_evaluation,\n",
    "    \"MODEL2_ANSWER\": model2_answers,\n",
    "    \"MODEL2_EVALUATION\": model2_evaluation,\n",
    "    \"MODEL1a_ANSWER\": model1a_answers,\n",
    "    \"MODEL1a_EVALUATION\": model1a_evaluation,\n",
    "    \"MODEL2a_ANSWER\": model2a_answers,\n",
    "    \"MODEL2a_EVALUATION\": model2a_evaluation\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_response_df.set_index(\"ID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_response_df.to_csv(\"evaluated_response_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsc-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
